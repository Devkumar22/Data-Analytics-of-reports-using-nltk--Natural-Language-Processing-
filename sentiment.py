# -*- coding: utf-8 -*-
"""sentiment.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11ZuUQHn8qh3W06SvYg3FNO1Nu1y5BCFC
"""

import numpy as np
import pandas as pd

from nltk.tokenize import sent_tokenize, word_tokenize
import nltk
nltk.download('punkt')
nltk.download('stopwords')

from nltk.corpus import stopwords

import re

from nltk.stem.porter import PorterStemmer
port = PorterStemmer()

from nltk.stem.wordnet import WordNetLemmatizer
nltk.download('wordnet')
wnet = WordNetLemmatizer()

from sklearn.feature_extraction.text import CountVectorizer
cv = CountVectorizer(ngram_range=(1,2), analyzer=lambda clear_text_5: clear_text_5, lowercase=False)

import urllib.request

constrain = pd.read_csv('/content/constraining_dictionary.xlsx - Sheet1.csv')
constrain=constrain['word'].tolist()
constraining_score = []

uncertain = pd.read_csv('/content/uncertainty_dictionary.xlsx - Sheet1.csv')
uncertain = uncertain['word'].tolist()
uncertainty_score = []

df = pd.read_csv('/content/cik_list_ajay.csv')
df['SECFNAME'] = 'https://www.sec.gov/Archives/' + df['SECFNAME'].astype(str)

positive_score = []
negative_score = []
polarity_score = []
percentage_of_complex_words = []
fog_index = []
complex_word_count = []
constraining_words_for_whole_report = []
constraining_word_proportion = []
uncertainty_word_proportion = []
average_sentence_length = []
word_count = []
positive_word_proportion = []
negative_word_proportion = []

from google.colab import files
df1 = df['SECFNAME']
df1.to_csv('df1.csv')
files.download('df1.csv')

len(dataslist)

counting=0
df3=pd.DataFrame()
df3=df["SECFNAME"]

import requests
from bs4 import BeautifulSoup as bs

linkdata=[]  
for links in df3:      
    req = requests.get(links)
    soup = bs(req.text, 'html.parser')
    s = soup.find_all()
    w=[]
    str_main = s[4:8]
    w.append(str_main)
    linkdata.append(w)
    counting+=1

dataslist=[]

for i in range(1,16):
    dataslist.append(data1)
    dataslist.append(data2)
    dataslist.append(data3)
    dataslist.append(data4)
    dataslist.append(data5)
    dataslist.append(data6)
    dataslist.append(data7)    
    dataslist.append(data8)
    dataslist.append(data9)    
    dataslist.append(data10)
dataslist.append(data4)
dataslist.append(data5)

data1= ["The Company markets a variety of products (primarily small kitchen appliances, personal care and comfort products, grills, professional clippers and related products ) outside the U.S. While the Company sells many of the same products domestically and internationally, it also sells products designed specifically to appeal to foreign markets. The Company, through its foreign subsidiaries, has manufacturing facilities in Mexico and Venezuela, and sales offices in Canada, the United Kingdom, Hong Kong and Australia. The Company international products are sourced from the Companys United States, Mexican or Venezuelan manufacturing operations or from vendors primarily located in Asia. International sales accounted for approximately 21% of the Company's total net sales in 1997.To date, the Company's activities outside the United States have been primarily focused in Mexico, Latin America and Canada. The Company enjoys a strong market position in a number of product categories in Latin America. The Oster/registered trademark/ brand has the leading market share in small appliances in a number of Latin American countries.he majority of Sunbeam sales are from products in which the Company holds the number one or two market share position. The Company believes that this combination of leading brand-name products and breadth of product offerings makes Sunbeam an attractive vendor to retailers who are consolidating their suppliers."]
data2=["State below in reasonable detail the reasons why Form 10-K, 11-K, 20- F, 10-Q, N-SAR or the transition report portion thereof could not be filed within the prescribed time period. As previously announced, the Audit Committee of the Board of Directors of Sunbeam Corporation (the Company) has determined that the Company will be required to restate its audited financial statements for 1997 and possibly 1996, as well as its unaudited financial statements for the first quarter of 1998.  This conclusion was reached by the Audit Committee based on information presented to it by the Company's outside auditor, Arthur Andersen LLP, and the accounting firm assisting the Audit Committee, Deloitte & Touche LLP.  The Company believes that it will be in a position to issue restated financial statements by the end of September 1998.  Until that time, the Company will not be in a position to report its financial results for the second quarter of 1998 and, accordingly, will be unable to file its second quarter Form 10-Q with the Commission"]
data3=[" In order to finance the acquisitions of Coleman, Signature Brands and First Alert and to repay substantially all of the outstanding indebtedness of the Company and the three acquired companies, the Company completed an offering of Zero Coupon Convertible Senior Subordinated Debentures due 2018 (the Debentures) at a yield to maturity of 5% (or approximately $2,014 million principal amount at maturity) on March 25, 1998, which netted approximately 730 million of proceeds to the Company, and the Company borrowed approximately 1,325 million under a new bank credit facility (the New Credit Facility)"]
data4=["On June 25, 1998, the Company announced that its auditor, Arthur Andersen LLP, would not consent to the inclusion of its opinion on the Company's 1997 financial statements in a registration statement the Company was planning to file with the SEC. On June 30, 1998, the Company announced that the Audit Committee of the Board of Directors would conduct a review of the Company's prior financial statements and that therefore, those financial statements should not be relied upon. The Company also announced that Deloitte & Touche LLP had been retained to assist the Audit Committee and Arthur Andersen in their review of the Company's prior financial statements. On August 6, 1998, the Company announced that the Audit Committee of the Board of Directors had determined that the Company would be required to restate its financial statements for 1997, the first quarter of 1998, and possibly 1996, and that the adjustments, while not then quantified, would be material. On October 20, 1998, the Company announced the restatement of its financial results for a six-quarter period from the fourth quarter of 1996 through the first quarter of 1998."]
data5=["The Company filed an amended 1997 Form 10-K/A on November 12, 1998 andis now in the process of preparing an amended Form 10-Q/A for the firstquarter of 1998, as well as the initial filing of its Form 10-Q for thesecond quarter of 1998, which, as disclosed in a Form 12b-25 filed with the Commission on August 13, 1998, the Company was not able to file timely. The Company anticipates making these filings prior to the filing of its third quarter 1998 Form 10-Q. As a result of the significant time and effort being expended by the Company and its advisors in connection with the preparation of the filingsreferred to above, however, the Company will not be in a position to file timely its third quarter 1998 Form 10-Q.  Nevertheless, the Company does intend to file its third quarter Form 10-Q no later than the fifth calendarday following the prescribed due date, as contemplated by Rule"]
data6=["For the first quarter of 1998, 4,758,565 shares related to stock options,(58,065) shares related to restricted stock and 13,150,000 shares related to the conversion feature of the Zero Coupon Convertible Senior Subordinated Debentures were not included in the diluted average common shares outstanding, as the effect would have been antidilutive. For the first quarter of 1997, the dilutive effect of 2,174,154 equivalent shares and (225,915) equivalent shares related to restricted stock were used in determining the dilutive average shares outstanding. SFAS No. 128 requires the use of dilutive potential common shares in the determination of diluted earnings per share if an entity reports earnings from continuing operations. Given Sunbeam's Loss from Discontinued Operations in the first quarter of 1997, the use of dilutive potential common shares in the determination of the diluted per share loss from discontinued operations and net loss per share is antidilutive. (See Note 10.)"]
data7=["In March 1998, the American Institute of Certified Public Accountants (AICPA) issued Statement of Position 98-1, ACCOUNTING FOR THE COSTS OF COMPUTER SOFTWARE DEVELOPED OR OBTAINED FOR INTERNAL USE (SOP 98-1). SOP 98-1 requires computer software costs associated with internal use software to be expensed as incurred until certain capitalization criteria are met. The Company will adopt SOP 98-1 on January 1, 1999. Adoption of this Statement is not expected to have a material impact on the Companys consolidated financial position or results of operations, although actual charges incurred may be material due to Year 2000 issues."]
data8=[" On March 30, 1998, the Company, through a wholly-owned subsidiary, acquired approximately 81% of the total number of then outstanding shares of common stock of Coleman from a subsidiary of MacAndrews & Forbes Holdings, Inc, in exchange for 14,099,749 shares of the Company's common stock and approximately $160 million in cash as well as the assumption of $1,016 million in debt. The value of the common stock issued at the date of acquisition ($524 million) was derived by using the average ending stock price as reported by the New York Stock Exchange Composite Tape for the day before and day of the public announcement of the acquisition, discounted by 15% due to the restrictive nature of the securities."]
data9=[" As previously detailed in Sunbeam Corporation's (the Company) filings with the Commission, the Company experienced substantial changes in its management and changed its outside auditors during the 1998 fiscal year. In addition, during the 1998 fiscal year, the Company restated its financial statements for the 1997 fiscal year and for the fourth quarter of 1996 and the first quarter of 1998. Both the Company's management and its auditors allocated substantial resources to these efforts."]
data10=["The Company and its subsidiaries are also involved in various lawsuits arising from time to time which the Company considers to be ordinary routine litigation incidental to its business. In the opinion of the Company, the resolution of these routine matters, and of certain matters relating to prior operations, individually or in the aggregate, will not have a material adverse effect upon the financial position, results of operations or cash flows of the Company."]

for links in dataslist:
    clear_text_1 = []
    for words in links:
        clear_text_1.append(words)
    clear_text_2 = []
    clear_text_2 = [ word_tokenize(i) for i in clear_text_1]

    clear_text_3 = []
    for words in clear_text_2:
        clean = []
        for w in words:
            res = re.sub(r'[^\w\s]', "", w)
            if res != '':
                clean.append(res)
        clear_text_3.append(clean)
    
    clear_text_4 = []
    for words in clear_text_3:
        w=[]
        for word in words:
            if not word in stopwords.words('english'):
                w.append(word)
        clear_text_4.append(w)
    
    clear_text_5 = []
    for words in clear_text_4:
        w=[]
        for word in words:
            w.append(word)
        clear_text_5.append(w) 
    
    wordcount=0
    average_sentence_len=0
    for i in clear_text_5:                          #wordcount-9
            wordcount=len(i)
    word_count.append(wordcount)
    average_sentence_len = wordcount/20         #Average Sentence length-5
    average_sentence_length.append(average_sentence_len)


    uncertainty=0
    uncertainty_word_prop=0
    for i in clear_text_5:
        for l in i:
            for k in uncertain:
                if k == l:                          #uncertainty-score-10
                    uncertainty+=1
    uncertainty_score.append(uncertainty)
    uncertainty_word_prop = uncertainty/wordcount   #uncertainty word proportion-14
    if wordcount > 0:
        uncertainty_word_prop = uncertainty/wordcount   #uncertainty word proportion-14
    else:
        uncertainty_word_prop = uncertainty

    uncertainty_word_proportion.append(uncertainty_word_prop)


    constraining=0
    constraining_word_prop=0
    constraining_words_for_whole_rep=0
    for i in clear_text_5:
        for l in i:                         #constraining-score-11
            for k in constrain:
                if k==l:
                    constraining+=1
    constraining_score.append(constraining)
    if wordcount > 0:
        constraining_word_prop = constraining/wordcount     #constraining word proportion-15
    else:
        constraining_word_prop = constraining
    constraining_word_proportion.append(constraining_word_prop)

    constraining_words_for_whole_rep = constraining            #Constrainingwordsforwholereport-16
    constraining_words_for_whole_report.append(constraining_words_for_whole_rep)


    syllable=0
    complex_word_cou=0
    fog_ind=0
    Percentage_of_Complex_wor=0
    for complexe in clear_text_5:
        for comp in complexe:
            syllable=sum(list(map(lambda x: 1 if x in ["a","i","e","o","u","y","A","E","I","O","U","y"] else 0,comp)))
            if syllable > 2:
                #print(syllable)                                        #complexwordount-8
                complex_word_cou+=1
    complex_word_count.append(complex_word_cou)
    if wordcount > 0:
        percentage_of_complex_wor = complex_word_cou/wordcount         #percentageofcomplexwords-6 
    else:
        percentage_of_complex_wor = complex_word_cou
    percentage_of_complex_words.append(percentage_of_complex_wor)
    fog_ind = 0.4 * (average_sentence_len + percentage_of_complex_wor)   #fogindex-7
    fog_index.append(fog_ind)


    X_vec = cv.fit_transform(clear_text_5).toarray()

    positive_sc=0
    negative_sc=0
    polarity_sc=0
    positive_word_prop=0
    negative_word_prop=0

    zero = sum(x==0 or x==2 or x==3 or x==4 or x==5 or x==6 or x==7 or x==8 or x==9 for row in X_vec for x in row)
    ones = sum(x == 1 for row in X_vec for x in row)
    

    positive_sc = ones                                 #positive_sore-2
    positive_score.append(positive_sc)
    negative_sc = zero                                       #negative_score-3
    negative_score.append(negative_sc)

    positive_word_prop = positive_sc/wordcount         #positive_word_proportion-12
    positive_word_proportion.append(positive_word_prop)

    negative_word_prop = negative_sc/wordcount         #negative_word_proportion-13
    negative_word_proportion.append(negative_word_prop)

    polarity_sc = (positive_sc-negative_sc)/ ((positive_sc + negative_sc) + 0.000001)    #polarityscore-4
    polarity_score.append(polarity_sc)


df['positive_score'] = positive_score
df['negative_score'] = negative_score
df['polarity_score'] = polarity_score
df['average_sentence_length'] = average_sentence_length
df['percentage_of_complex_words'] = percentage_of_complex_words
df['fog_index'] = fog_index
df['complex_word_count'] = complex_word_count
df['word_count'] = word_count
df['uncertainty_score'] = uncertainty_score
df['constraining_score'] = constraining_score
df['positive_word_proportion'] = positive_word_proportion
df['negative_word_proportion'] = negative_word_proportion
df['uncertainty_word_proportion'] = uncertainty_word_proportion
df['constraining_word_proportion'] = constraining_word_proportion
df['constraining_words_for_whole_report'] = constraining_words_for_whole_report

df.head()

from google.colab import files
df.to_csv('df.csv')
files.download('df.csv')

len(positive_score)

len(average_sentence_length)

percentage_of_complex_words